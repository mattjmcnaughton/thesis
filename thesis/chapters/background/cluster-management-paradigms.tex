As was briefly mentioned in the introduction, cluster managers are responsible
for admitting, scheduling, running, maintaining, and monitoring all applications
and jobs a user wishes to run on the cluster. Naturally, cluster managers are
extremely diverse, both in the types of applications and jobs they are most
suited to running, and the method in which they seek execute their duties.
At the most basic level, there are two types of workload that may be submitted
to a cluster manager: production and batch. Production tasks are long-running
with strict performance requirements and penalties to downtime. Batch tasks are
more flexible in their ability to handle short-term performance variance. In the
context of a large company like Google, a production task would be serving a
large website like Gmail, which must be continuously accessible with low-latency
and little downtime. A batch task would be analysing advertising analytics data
with MapReduce, which can fail or slow without significant external
costs.\cite[pg. 1]{borg} The type of tasks a cluster management system
predominantly seeks to run dictate the cluster manager's implementation details.

One important decision in the implementation of a cluster manager is the manner
by which the cluster manager schedules jobs.\footnote{Scheduling jobs on
machines simply equates to assigning jobs to resources on a machine.}  There exist three
different methods of scheduling: monolithic, two-level, and
shared state. With monolithic scheduling, a single algorithm
is responsible for taking the resource requests of all jobs and assigning them
to the proper machine. With two-level scheduling, the cluster manager simply
offers resources, which can then be accepted or rejected by the distributed
computing frameworks.\footnote{Distributed computing frameworks are frameworks
built to function over multiple machines: Apache Hadoop, Apache Spark\dots}
Finally, with shared state scheduling, multiple different algorithms concurrently work to
schedule jobs on the cluster.\cite[pg. 1]{omega} Naturally, all
of these methods have positives and negatives. While monolithic scheduling is
simple to initially, a single-threaded monolithic scheduler does not allow
nuanced processing of jobs. Attempts to add this nuance can create an incredibly
complicated algorithm that is difficult to extend.\cite[pg. 353-354]{omega}
While two-level scheduling is lightweight, simple, and offers advantages with respect to
data locality, it is not effective for long-running,
production jobs. Finally, while shared state scheduling removes the scheduler as
both a computational and complexity bottleneck, yet must take steps to guarantee
global properties of the cluster.\cite[pg. 363]{omega}
The ultimate determined method of assigning a job
resources effects the type of applications and distributed computing frameworks
runnable on the cluster manager and the efficiency with which these applications
and frameworks run.

A final distinction is licensing and availability of the cluster manager's code.
Because entities need cluster managers only to process and store massive amounts
of data and human-computer interaction, mainly large
corporations develop and utilize cluster managers. Often these cluster
managers are kept within the confines of the corporation, or only explained by a
brief paper or conference talk, with little source code available. In more
unique cases, the company will open-source the source code, allowing anyone to
view, modify, and run the cluster manager. Such open-sourcing presents a unique opportunity
for researchers wishing to experiment with cluster managers, yet without the
resources to create their own from scratch. In rarer instances, a
fully-developed cluster manager will originate from academic research. In unique
scenarios, a large corporation will use this cluster manager and the full code will
be open-sourced. The availability of source code directly impacts the
feasibility of pursuing experiments with an already existing cluster management
system.

Naturally, cluster managers can vary in multiple additional ways. However,
the previous three differences recognize the most important distinctions in this
thesis' context. Given this understanding, we can know begin to examine specific
cluster management implementations and defend our choice of Kubernetes as the
cluster manager on which we will ask and answer our research question.

\subsection{Borg}

\input{chapters/background/cluster-management-paradigms/borg}

\subsection{Omega}

\input{chapters/background/cluster-management-paradigms/omega}

\input{chapters/background/cluster-management-paradigms/comparison-table}

\subsection{Mesos}

\input{chapters/background/cluster-management-paradigms/mesos}

\subsection{YARN}

\input{chapters/background/cluster-management-paradigms/yarn}

\subsection{Kubernetes}

\input{chapters/background/cluster-management-paradigms/kubernetes}
