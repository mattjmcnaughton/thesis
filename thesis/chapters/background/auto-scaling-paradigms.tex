We now consider a subset of cluster management closely related to
this thesis' goal of ensuring efficient resource utilization and quality of
service. Specifically, we introduce
auto-scaling, a method of ensuring each application has the necessary amount
of computational resources to handle vary external
demands.\footnote{Importantly, auto-scaling is
made possible by current models of cluster\/cloud computing, in which it is
possible to automatically obtain and relinquish computing resources within a
very short time frame. Obviously, if adding computing resources required buying
a new physical server, as was the case before the advent of cloud computing,
auto-scaling becomes impossible.}

To better understand both the implementation and benefits of auto-scaling, let
us consider a simple scenario. Imagine you have an application running on a
cluster for a week. On Monday, it will need $x$ resources.\footnote{By
  \textit{resources}, we mean CPU, memory\dots} On Tuesday through
Thursday, the application will need $2x$ resources. Finally, on Friday the
application will again need $x$ resources. Without auto-scaling, we are forced
to assign a constant amount of resources to the application running on our
cluster. However, there is no constant amount of resources that can meet
the two goals of efficiently utilizing the cluster's resources and ensuring the
application has the resources needed for maintaining a high-level of service.
Specifically, if we assign the application $x$ resources,
then on Tuesday through Thursday the
application will not have the amount of resources it needs to handle its load,
and quality of service will deteriorate. Alternatively, if we assign the
application $2x$ resources on the cluster, than on Monday and Friday we will
essentially be wasting $x$ resources on the cluster, as they are assigned to an
application that does not need them. Such waste means a failure of efficient
resource utilization.

We address the inability to find a static amount of resources efficiently
handling all the variances in application load through auto-scaling.
Auto-scaling allows us to assign an application more or less resources on the
cluster factors. In our previous example, perfect auto-scaling
would allow us to assign the cluster $x$ resources on Monday and Friday and
$2x$ resources on Tuesday through Thursday. Through auto-scaling, we accomplish
both goals: our application has the needed resources for a high quality
of service, and our cluster is efficiently utilizing resources by only
allocating the application what it needs.
Overall, auto-scaling can make applications on a cluster more performant and
the cluster more cost-effective.

Given an understanding of the importance of auto-scaling, we now begin the
examine the differing implementations of auto-scaling. Auto-scaling
implementations differ in how the cluster manager assigns an application the new resources it
needs\footnote{Auto-scaling implementations can also take away resources from
an application running on a cluster.} and how the cluster manager decides to
assign the application the resources it needs. Given these two points of
variation, there are two predominant characteristics shaping the nature of an autoscaling
implementation. The first is if the auto-scaling is horizontal or vertical. The
second is if the auto-scaling is reactive or predictive.

\begin{enumerate}
  \item \underline{Horizontal vs. Vertical}: We begin by examining
    the difference between horizontal and vertical scaling.
    Let us begin by assuming there is an application assigned $x$ resources by the
    cluster manager. The application
    now faces external load such that it needs $2x$ resources to operate with an
    acceptable quality of service. There are now two options. In
    \textit{vertical} auto-scaling, the cluster manager will attempt to assign
    the application the needed $2x$ resources
    without halting the execution of the application. In \textit{horizontal}
    auto-scaling, the cluster manager will create another instance of
    the application, so that there are now two machines each with
    $x$ resources ($2x$ resources in summation). The load will now be split between
    the two new instances of the application, meaning each machine now handles half
    the requests and requires only the $x$ resources it has.\cite[pg.
    4]{auto-scaling-techniques-for-elastic-applications-in-cloud-environments} While
    both of these variations of auto-scaling accomplish the same purpose, horizontal
    auto-scaling is much simpler. Given we know how to create an instance of a
    virtual machine running the application, an entirely safe assumption
    considering we already created one such instance, it is fairly trivial to create
    another instance, and then split the load between these two instances using
    standard methods of load balancing. \footnote{Claiming
    simplicity assumes the application is written
    such that it can be replicated with no unexpected modifications
    on operation.} Contrast this well-defined duplication with the more questionable, difficult
    process of changing the resources given to a virtual machine without stopping
    the execution of the application. Importantly, there exists
    no consistent, cross-platform method of
    modifying the amount of resources granted to a virtual machine instance without
    stopping the execution of the virtual machine. As such, vertical auto-scaling is
    rarely seen in practice; every implementation of
    auto-scaling we examine focuses on horizontal auto-scaling.\cite[pg.
    4]{auto-scaling-techniques-for-elastic-applications-in-cloud-environments}

  \item \underline{Reactive vs. Predictive}: We continue by
    examining the distinction between reactive and predictive
    auto-scaling. At the simplest level, reactive auto-scaling reacts to
    the current state of the application and cluster, while predictive
    auto-scaling reacts to the future state of the application and cluster.\cite[pg.
    12]{auto-scaling-techniques-for-elastic-applications-in-cloud-environments}
    While reactive auto-scaling must only consider one
    time-frame when gathering and interpreting information, predictive
    auto-scaling must consider many different time-frames with respect to the
    most accurate method of projecting past metrics into future metrics. However,
    predictive auto-scaling has the advantages both of historical insight and allowing
    the cluster manager to decrease the time-costs of certain actions by performing
    them before a reactive cluster manager would suggest.\footnote{We will spend
    considerable time later in this concept. Basically, predictive auto-scaling
    makes it easier to account for the amount of time necessary to perform
    horizontal auto-scaling (i.e. creating a new virtual machine instance running
    the application). If we know we need a machine in the future, we can start
    creating it before it is needed, so it is ready by the time it is needed. With reactive
    auto-scaling, we do not know we need the replication until the current state of
    the application and cluster indicates it. Thus, we must wait for the
    application to be created and ready to run,
    all the while the application will be operating with
    sub-optimal resources.}
    Finally, techniques for auto-scaling can be both reactive and predictive as
    they incorporate both current and projected cluster and application metrics
    to make auto-scaling decisions.
\end{enumerate}

A number of the major providers of cloud computing resources offer auto-scaling.
The most prominent of these providers is Amazon, which supports threshold-based
horizontal auto-scaling on EC2 virtual machine
instances.\cite{amazon-auto-scaling-developer-guide} Furthermore, Netflix
implements time-series analysis auto-scaling to help it respond to the
varying demand placed on its services throughout the
day.\cite{netflix-scryer-part-i} Finally, Kubernetes
implements control-theory auto-scaling.\cite{k8s-horizontal-pod-autoscaler-proposal}
We will examine threshold, time-series analysis, and control-theory
auto-scaling in detail in the remainder of this section.

\input{chapters/background/auto-scaling-paradigms/comparison-table}

\subsection{Threshold-based Rule Policies}

\input{chapters/background/auto-scaling-paradigms/threshold-based-rule-policies}

\subsection{Time-series Analysis}

\input{chapters/background/auto-scaling-paradigms/time-series-analysis}

\subsection{Control theory}

\input{chapters/background/auto-scaling-paradigms/control-theory}
