We now proceed to consider a subset of cluster management closely related to
this thesis' goal of ensuring high quality of service in the face of changing
external factors and efficient resource utilization. Specifically, we introduce
auto-scaling, a method of ensuring each application has the necessary amount
of resources to handle its varying load.\footnote{Importantly, auto-scaling is
made possible by current models of cluster\/cloud computing, in which it is
possible to automatically obtain and relinquish computing resources within a
very short time frame. Obviously, if adding computing resources required buying
a new physical server, as was the case before the advent of cloud computing,
auto-scaling becomes impossible.}

To better understand both the implementation and benefits of auto-scaling, let
us consider a simple scenario. Imagine you have an application running on a
cluster for a week. On Monday, it will need $x$ resources.\footnote{By
  \textit{resources}, we mean CPU, memory\dots} On Tuesday through
Thursday, the application will need $2x$ resources. Finally, on Friday the
application will again need $x$ resources. Without auto-scaling, we are forced
to assign a constant amount of resources to the application running on our
cluster. However, there is no constant amount of resources that can meet
the two goals of efficiently utilizing the cluster's resources and ensuring the
application has the resources it needs to maintain a high-level of service. If
we assign the application $x$ resources, then on Tuesday through Thursday the
application will not have the amount of resources it needs to handle its load,
and quality of service will deteriorate. Alternatively, if we assign the
application $2x$ resources on the cluster, than on Monday and Friday we will
essentially be wasting $x$ resources on the cluster, as they are assigned to an
application that does not need them. This waste prevents reaching our goal of
efficiently utilizing the cluster's resources.

We address the inability to find a static amount of resources efficiently
handling all the variances in application load through auto-scaling.
Auto-scaling allows us to assign an application more or less resources on the
cluster based on varying external factors. In our previous example, auto-scaling
would allow us to assign the cluster $x$ resources on Monday and Friday and
$2x$ resources on Tuesday through Thursday. Through auto-scaling, we accomplish
both goals: our application has the resources it needs to ensure a high quality
of service, and our application is not inefficiently holding cluster resources
that it does not need. Overall, Auto-scaling can make applications on a cluster more
cost-effective and more performant.

Given an understanding of the importance of auto-scaling, we now begin the
examine the differing implementations of auto-scaling. Auto-scaling
implementations differ in how they assign an application the new resources it
needs\footnote{Auto-scaling implementations can also take away resources from
an application running on a cluster.} and how they decide to
assign the application the resources it needs.
There are two predominant characteristics shaping the nature of an autoscaling
implementation. The first is if the auto-scaling is horizontal or vertical. The
second is if the auto-scaling is reactive or predictive.

We begin by examining the difference between horizontal and vertical scaling.
Let us begin by assuming there is an application running on a virtual machine
instance assigned by the cluster with $x$ amount of resources. The application
now faces external load such that the current amount of resources assigned to
the application is not sufficient. Rather, let us assume the application now
needs $2x$ resources to function efficiently. There are now two options. In
\textit{vertical} auto-scaling, the cluster manager will attempt to assign the
virtual machine instance running the application the needed $2x$ resources
without halting the execution of the application. In \textit{horizontal}
auto-scaling, the cluster manager will create another instance of the virtual
machine running the application, so that there are now two machines each with
$x$ resources ($2x$ resources in summation). The load will now be split between
the two new instances of the application, meaning each machine must only handle
requests requiring the $x$ resources each individual virtual machine instance
has.\cite[pg.
4]{auto-scaling-techniques-for-elastic-applications-in-cloud-environments} While
both of these variations of auto-scaling accomplish the same purpose, horizontal
auto-scaling is much simpler. Given we know how to create an instance of a
virtual machine running the application, which is an entirely safe assumption
considering we already created one such instance, it is fairly trivial to create
another instance, and then split the load between these two instances using
standard methods of load balancing. This
statement of simplicity of course assumes the application is written in a
scalable manner such that it can be replicated with no unexpected modifications
on operation. Contrast this well-defined with more questionable, difficult
process of changing the resources given to a virtual machine without stopping
the application from executing. Importantly, there exists
no consistent, cross-platform method of
modifying the amount of resources granted to a virtual machine instance without
stopping the execution of the virtual machine. As a result, every method of
auto-scaling we examine focuses on horizontal auto-scaling.\cite[pg.
4]{auto-scaling-techniques-for-elastic-applications-in-cloud-environments}

We continue by examining the distinction between reactive and predictive
auto-scaling. At the simplest level, \textit{reactive} auto-scaling reacts to
the current state of the application and cluster, while \textit{predictive}
auto-scaling predicts the current state of the application and cluster.\cite[pg.
12]{auto-scaling-techniques-for-elastic-applications-in-cloud-environments}
Predictive auto-scaling can be based on a number of different metrics and
methods of prediction, which highlights some of the inherent complexity of
predictive auto-scaling. While reactive auto-scaling must only consider one
method of gathering and interpreting information, when attempting predictive
auto-scaling there are many decisions that must be made with respect to the
most accurate method of projecting past metrics into future metrics. However,
predictive auto-scaling has the advantages both of incorporating greater amounts
of past information which may be able to provide historical insight and allowing
the cluster manager to decrease the time-costs of certain actions by performing
them before a reactive cluster manager would suggest.\footnote{We will spend
considerable time later in this concept. Basically, predictive auto-scaling
makes it easier to account for the amount of time necessary to perform
horizontal auto-scaling (i.e. creating a new virtual machine instance running
the application). If we know we need a machine in the future, we can start
creating it now, so it is ready by the time it is needed. With reactive
auto-scaling, we do not know we need the replication until the current state of
the application and cluster indicates it. Thus, we must wait for the
auto-scaling to occur, all the while the application will be operating with
sub-optimal resources.}
Finally, techniques for auto-scaling can be both reactive and predictive as
they incorporate both current and projected cluster and application information
to make auto-scaling decisions.

A number of the major providers of cloud computing resources offer auto-scaling.
The most prominent of these providers is Amazon, which supports threshold-based
horizontal auto-scaling on EC2 virtual machine
instances.\cite{amazon-auto-scaling-developer-guide} Furthermore, Netflix
implements time-series analysis auto-scaling to help it respond to the
varying demand placed on its services throughout the
day.\cite{netflix-scryer-part-i} Finally, Kubernetes
implements control-theory auto-scaling.\cite{k8s-horizontal-pod-autoscaler-proposal}
We will examine threshold, time-series analysis, and control-theory
auto-scaling in detail in the remainder of this section.

\input{chapters/background/auto-scaling-paradigms/comparison-table}

\subsection{Threshold-based Rule Policies}

\input{chapters/background/auto-scaling-paradigms/threshold-based-rule-policies}

\subsection{Time-series Analysis}

\input{chapters/background/auto-scaling-paradigms/time-series-analysis}

\subsection{Control theory}

\input{chapters/background/auto-scaling-paradigms/control-theory}
