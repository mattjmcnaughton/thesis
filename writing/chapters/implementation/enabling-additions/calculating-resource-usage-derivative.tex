The addition to record pod initialization time described in the
previous section tell us how far into the future
we want to predict the resource usage of the application. However, we still need
a method of predicting the resource usage of the application at this point in
time.

To start, we implement a simple method of linear prediction. Given the usage of
percent CPU utilization as the metric dictating when auto-scaling occurs, we
predict the future resource utilization of the cluster by first estimating the
derivative of average percent CPU utilization for all pods, and then adding the
derivative multipled by the average pod initialization time to the average current CPU
utilization percentage for all pod. Assuming a generally linear variation in CPU
utilization percentage, the result of this calculation will be the average resource
utilization of the pods after the interval of pod initialization time.

It is necessary to make a couple of changes to the Kubernetes code base in order
to faciliatate the calculation of resource utilization's derivative. To start,
consider the contents of a \textit{HorizontalPodAutoscaler} object, which is
just an Kubernetes api object representing an auto-scaler. This object contains
two objects entitled \textit{HorizontalPodAutoscalerSpec} and
\textit{HorizontalPodAutoscalerStatus}. Traditionally within
Kubernetes, \textit{Spec} represents the desired state of the object and
\textit{State} represents the current state of the object. Before the addition
of predictive auto-scaling, the \textit{HorizontalPodAutoscalerStatus} object
contained fields for the current and desired number of replicas, the last time
at which scaling occured, and the current average CPU utilization percentage for
all pods controlled by this auto-scaler object. This last field, entitled
\textit{CurrentCPUUtilizationPercentage}, provides part of the information
needed to estimate the average derivative of CPU utilization
percentage \cite{k8s-horizontal-pod-autoscaler-object}.
However, to make any estimation, we need to know at least one previous average
CPU utilization percentage value and the time at which said value was
observed.

Thus, we add a new field to the \textit{HorizontalPodAutoscalerStatus} object
entitled \textit{PreviousCPUUtilizationPercentage}. It is identical to the
\textit{CurrentCPUUtilizationPercentage} field with respect to integer type, yet
differs in that it \textit{PreviousCPUUtilizationPercentage} represents the
average CPU utilization percentage value at the previous observation time.
Already Kubernetes implements code that updates the
\textit{HorizontalPodAutoscalerStatus} object at a set duration interval. Our
addition modifies the current code such that during this update, before the value of
\textit{CurrentCPUUtilizationPercentage} is updated with the new value,
\textit{CurrentCPUUtilizationPercentage} is copied to
\textit{PreviousCPUUtilizationPercentage}. In other words, at time
$t_{i}$, the \textit{HorizontalPodAutoscalerStatus} object will have access to
CPU utilization percentage values for $t_{i}$ and $t_{i - 1}$. Given that the
interval between these observational values is constant, we now have all of the
information necessary to estimate the derivative of CPU utilization percentage
in the previously described manner.

%% @TODO Should I just go ahead and implement it with a queue?

While not immediately pursued in this implementation, the derivative of average
CPU utilization percentage could perhaps be estimated with greater accuracy if
more previous values were recorded. For example,
\textit{PreviousCPUUtilizationPercentage} could be renamed
\textit{PreviousCPUUtilizationPercentages} and instead of being a single integer
value, it could be a queue containing integers. The queue would have some set
size, $n$, and if the queue was full, the least recent observation would be
removed. The use of a queue data structure would support calculating the
derivative based on CPU utilization percentage values for times $t_{i} \cdots
t_{i - n}$. Ultimately, for concerns of initial simplicity, this method was not
pursued, but it is interesting to consider if it would result in a more accurage
prediction of future resource usage.

The success of predictive auto-scaling in Kubernetes depends on greatly on the
accuracy of future predictions of resource utilization. The accuracy of the
linear prediction mechanism described here will be examined in the evaluation
section, as well as the accuracy of other slight variations.
