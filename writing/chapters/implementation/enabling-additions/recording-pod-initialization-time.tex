This thesis' implementation of predictive auto-scaling uses
\code{PodInitializationTime} to determine at which future time we should predict
resource utilization. As was made explicit in section
\ref{architecture-predictive-autoscaling-in-relation-to-kubernetes-benefits-of-predictive-autoscaling},
this time frame allows any replica pods created to be ready to share in the work by the
time they are needed.

Pod \textit{initialization} time is distinct from pod \textit{creation} time and
the idea of a pod \textit{running}. We define an initialized pod as one that is
ready to perform computational work. This contrasts with a \textit{created} pod,
which indicates that all the containers within the pod are created. It
does not signify that these containers have started running, performed any
initialization tasks, and are now ready to share in computational work. The time
necessary to create all containers for a pod is not equal to the time necessary
for all containers within the pod to perform their computational work.
Furthermore, a \textit{running} pod is merely a pod in which all containers have
been created, and at least one container is running or in the process of
starting. This description does not guarantee that the containers have started
and are ready to perform work \cite{k8s-pod-states}.

Fortunately, Kubernetes defines the idea of a \textit{Readiness Probe}. A
readiness probe shows whether a pod is ready to handle incoming requests.
Services use this probe to determine whether to pass work along to a
replica pod. In doing so, services ensure that pods with long startup times do not
receive proxy traffic until ready to handle it. Pods must implement a readiness
probe, or else it will be assumed that if the pod is running, it is ready
\cite{k8s-pod-states}. Each container within a pod defines its own readiness
probe, by specifying an HTTP endpoint that will return a successful HTTP status
code when sent a GET request if the replica pod is ready
\cite{k8s-working-with-containers}.\footnote{There are alternative methods of
defining a readiness probe, but specifying an HTTP endpoint is the most logical
within the context of this thesis.} In terms of this thesis, a
pod being \textit{ready} and a pod being \textit{initialized} are analogous
terms.

While Kubernetes did not previously record \code{PodInitializationTime},
we can rely on the existence of the readiness probe to
determine this value. Each pod records the time at which it was first ordered into
existence. Subtracting the time at which the pod first came into existence
from the time at which a request to the readiness probe was first successful
results in the pod initialization time we desire. However, while Kubernetes
records the time at which the pod first came into existence as
\code{pod.CreationTimestamp}, it does not record the time at which the
readiness probe first returned \textit{Success}. Fortunately, Kubernetes pods
record their current state, all states in which they have been, and the time
at which they assumed said states. As such, the following algorithm
calculates the average initialization time for all pods controlled by the auto-scaler.

\begin{itemize}
  \item For all pods controlled by the auto-scaler.
    \begin{itemize}
      \item If the pod was ever in the ready state, find the first time that
        event occurred. If the pod has never been in the ready state, skip this pod.
      \item If an \code{InitializationTime} value has not already been recorded for
        this pod, then subtract the \code{CreationTime} from the time at which the
        pod entered the ready phase, and record this time as
        \code{InitializationTime}.
      \item Add the value for \code{InitializationTime} to
        \code{TotalInitializationTime}.
      \end{itemize}
    \item Divide \code{TotalInitializationTime} by the total number of pods that
      have been ready at some point.
\end{itemize}

This algorithm allows us to record the initialization time for each pod
controlled by the auto-scaler, as well as calculate the average pod
initialization time for all pods controlled by this auto-scaler.\footnote{We
record the value in the \code{Annotations} map for each pod,
which is basically a map for writing
values that are not necessarily in the \code{Pod} API object. If predictive
auto-scaling becomes particularly popular, \code{InitializationTime} may be
included as a field in the \code{Pod} API object, although making such a change would
be a fairly substantial process.}

At this point, all recorded initialization time values factor into the average.
This inclusion could lead to a problem with extreme outliers drastically
affecting the average value. Perhaps in future iterations of predictive pod
auto-scaling it would make sense to only average values that fit within some
multiple of the standard deviation.

With this implementation, we can now use initialization time to determine how
far into the future to predict the state of the application on the cluster, and
thus how far into the future to auto-scale.
