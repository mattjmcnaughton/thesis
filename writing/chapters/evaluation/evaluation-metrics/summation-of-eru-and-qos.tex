We are most interested in testing for an improvement in the summation of
efficient resource utilization and quality of service metrics. It is
easy to improve quality of service by decreasing efficient resource
utilization, as we can just assign the application the largest amount of
resources it could ever need. It is equally easy to improve efficient resource
utilization by decreasing quality of service, as we can just assign an
application the fewest amount of resources it will ever use. As such, we want to
ensure that this thesis improves efficient resource utilization or quality of
service, without negatively impacting the other. This realization leads us to
evaluating our modifications to auto-scaling by measuring its impact on the
summation of efficient resource utilization and quality of service.

While conceptually summing efficient resource utilization and quality of service
is simple, care must be taken when combining the specific metrics of
\code{IdleCPU} and \code{ResponseTime}. The metrics are measured in unrelated
units. Furthermore, the scale for these metrics may be entirely different,
meaning that small changes in one could completely overshadow larger changes in
the other. Additionally, for both \code{IdleCPU} and \code{ResponseTime} low
measures are desirable, while intuitively with summation of ERU and QoS, high
measures are desirable.

We combine these ERU and QoS measurements through the following process.
First, we gather all measurements of ERU and QoS,
distinguished by the variables $E_{A}$ and $Q_{A}$ respectively, from our
predictive and reactive measurements for a single combination of independent
variables. Next, we define $e_{t}$ and $q_{t}$ as the
respective ERU and QoS measurements at time $t$. We first
normalize these measurements through calculating their respective z-scores,
by first subtracting the individual observation value
from the mean of all observations, and then dividing by the standard deviation of all
observations. This operation leaves us with $ne_{t}$ and $nq_{t}$ respectively.
Our next step relates to how we interpet measurements for ERU and QoS, and how
we interpret measurements for the summation of ERU and QoS. With the current
metrics we use for measuring ERU and QoS individually, smaller values indicate
``better'' performance. However, with the summation of ERU and QoS, it makes
intuitive sense that higher values should indicate ``better'' performance.
Thus, we negate $ne_{t}$ and $nq_{t}$, before we finally sum
$-ne_{t}$ and $-nq_{t}$ together to get $s_{t}$, where $s_{t}$ is the summation
of ERU and QoS at time $t$.
In short, we add the negation of the z-score for
ERU and QoS. Mathematically, this process can be written as
follows:

\begin{align*}
  ne_{t} &= ((e_{t} - \mbox{MEAN}(E_{A})) / \mbox{STDDEV}(E_{A})) \\
  nq_{t} &= ((q_{t} - \mbox{MEAN}(Q_{A})) / \mbox{STDDEV}(Q_{A})) \\
  s_{t} &= -ne_{t} + -nq_{t}
\end{align*}

Given a measurement of the summation of ERU and QoS for a set
of observations, in which ERU and QoS have an equal impact in
the summation, it is now possible to compare the summations of ERU and
QoS within the different scaling methods or traffic patterns included
in our evaluation trials.
