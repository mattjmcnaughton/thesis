As will be discussed in detail in section \ref{evaluation-methodology-tools},
we've created a web server application that allows us to specify any \textit{pod
initialization time} we desire. As such, we have considerable flexibility with
respect to what initialization time values we test. To begin, we decided to test the
following value of 135s.

We initially believed 5s and 135s would be important independent variables to test because they
are indicative of different classes of applications that could be run on
Kubernetes. A pod initialization time of 5s is commonly found among web
application frameworks, as we showed when writing a simple HTTP server in Go and
using the Spring Java web application framework \cite{spring}. These web
frameworks initialized, and were ready to serve requests, in 1s and 5s
respectively. It is our belief that any web framework that simply
needs to initialize, without any external communicating of data, will
accomplish this task in under 5s. Thus, testing a pod initialization time of 5s
would allow us to consider how any web application framework would perform with
predictive auto-scaling. However, when pod initialization time is as little as
5s, there is essentially no difference between predictive and reactive
auto-scaling, particularly because we aggregate all of our measurements over a
one minute interval. The difference is particularly nonexistent, because
Kubernetes imposes a multi-minute threshold between auto-scalings.
As such, while 5s is a representative time value, it is not
one for which predictive auto-scaling's behavior is particularly interesting.

We derive a pod initialization time of 135s from a simulation of downloading a
shard database file, loading it into a database, and then starting a web
application to process data from said database. More specifically, our sample
pod downloaded a 25.2MB file and then batch inserted it into an Elasticsearch
database \cite{elasticsearch}. It then started a web application framework. In
all, this process took approximately 135s, although it is easy to imagine the
time varying based on the size of the initial shard file. The file we downloaded
came from an Elasticsearch tutorial on pre-populating a database
\cite{elasticsearch-import-some-data}, and thus we believe it is a fairly
representative size. By examining the pod initialization time of 5s, we
are confident that we are capturing the majority of the potential interesting use cases for
predictive auto-scaling.

We believe that there will be a sweet spot of pod initialization times
for which predictive auto-scaling demonstrates the most benefits over reactive
auto-scaling. Obviously the smaller the pod initialization time value, the lesser
the difference between reactive and predictive auto-scaling.
However, the larger the pod initialization time value, the further into
the future we must predict the state of the application. While large pod
initialization times have the potential for considerable benefits when using
predictive auto-scaling, we can only realize that potential if predictions of
future application state are accurate. As the prediction window gets larger and
larger, accuracy becomes substantially more difficult to obtain.
