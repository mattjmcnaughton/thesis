The first, and the simplest method, of scaling pods is \textit{static}
provisioning. Static provisioning requires one wishing to deploy an application on
Kubernetes to determine ahead of time a constant amount of pods for that
application. Any desire to update that static value will require a manual
change. Put simply, with the static method there will be a constant number of
pods, and the application will have a constant amount of resources, throughout
its entire lifetime, regardless of the amount of work the application is asked
to perform.

There are multiple possible heuristics for statically assigning resources to an
applications, as it is possible to over, under, or average provision.

\begin{itemize}
  \item \textbf{Over Provision}: With over provisioning, an application is given
    the greatest amount of resources that it will ever require. With respect to
    horizontal pod auto-scaling, over provisioning means the user of the
    application statically sets the replication controller to ensure that $x$ pods
    always exist, where $x$ is the number of pods needed to
    maintain high quality of service when the application is
    asked to perform the most work.\footnote{In this discussion, references to
    \textit{most}, \textit{least}, and \textit{average} work assume that there
    exist bounds on the work the external environment can ask the application to
    do.} While over provisioning ensures a high quality of service, it has extremely
    poor efficient resource utilization.

  \item \textbf{Under Provision}: With under provisioning, an application is
    given the least amount of resources that it will ever require. Again, in the
    context of horizontal pod auto-scaling, under provisioning leads to user to
    statically set the replication controller to ensure the existence of
    $y$ pods, where $y$ is the number of pods needed to maintain quality of
    service when the application is asked to perform the least work. Under
    provisioning ensures efficient resource utilization, as the application will
    never reserve any resources and then leave them idle. However, in all
    situations except for when the application performs the minimum possible
    amount of work, quality of service will suffer because the application does
    not have enough resources.

  \item \textbf{Average Provision}: With average provisioning, an application is
    given the average amount of resources that it needs. With respect to
    horizontal pod auto-scaling, average provisioning guides the user to
    statically set the replication controller to maintain $z$ pods, where
    $z$ is the number of pods needed to maintain quality of service when the
    application is asked to perform the average amount of work. Average
    provisioning can be seen as somewhat of a middle ground between under and
    over provisioning, offering decent quality of service and efficient resource
    utilization.
\end{itemize}

Ultimately, we do not devote significant time to
considering any type of static provisioning, as we are confident that it will at
best be equal to reactive auto-scaling. Thus if our implementation of predictive
auto-scaling outperforms reactive auto-scaling, we are confident that it will
also outperform any type of static provisioning.
